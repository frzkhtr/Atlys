{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midv500\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './midv500_data/'\n",
    "export_dir = \"midv500\"\n",
    "filename = 'midv500'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_images_per_type(dataset_path):\n",
    "    document_types = {}\n",
    "\n",
    "    # Traverse through each labeled folder (e.g., '01_alb_id', '02_bra_passport', ...)\n",
    "    for label_folder in os.listdir(dataset_path):\n",
    "        label_folder_path = os.path.join(dataset_path, label_folder)\n",
    "        if not os.path.isdir(label_folder_path):\n",
    "            continue\n",
    "        \n",
    "        # Traverse through each document type folder (e.g., 'images/CA', 'images/CS', ...)\n",
    "        images_folder = os.path.join(label_folder_path, 'images')\n",
    "        if not os.path.exists(images_folder):\n",
    "            continue\n",
    "        \n",
    "        for doc_type_folder in os.listdir(images_folder):\n",
    "            doc_type_folder_path = os.path.join(images_folder, doc_type_folder)\n",
    "            if not os.path.isdir(doc_type_folder_path):\n",
    "                continue\n",
    "            \n",
    "            # Count the number of images in this document type folder\n",
    "            num_images = len([name for name in os.listdir(doc_type_folder_path) if os.path.isfile(os.path.join(doc_type_folder_path, name))])\n",
    "            \n",
    "            # Store the count in dictionary\n",
    "            if label_folder not in document_types:\n",
    "                document_types[label_folder] = {}\n",
    "            \n",
    "            document_types[label_folder][doc_type_folder] = num_images\n",
    "    \n",
    "    return document_types\n",
    "\n",
    "# Example usage\n",
    "dataset_path = '.\\midv500_data\\midv500'\n",
    "document_counts = count_images_per_type(dataset_path)\n",
    "\n",
    "# Print document type counts\n",
    "image_count_dict = {}\n",
    "total_count = 0\n",
    "for label_folder, doc_counts in document_counts.items():\n",
    "    image_count_dict[label_folder] = {}\n",
    "    label_folder_count = 0\n",
    "    # print(f\"Label Folder: {label_folder}\")\n",
    "    for doc_type, count in doc_counts.items():\n",
    "        image_count_dict[label_folder][doc_type] = count\n",
    "        label_folder_count += count\n",
    "        # print(f\"  {doc_type}: {count} images\")\n",
    "    image_count_dict[label_folder]['total_count'] = label_folder_count\n",
    "    total_count += label_folder_count\n",
    "image_count_dict['total_count'] = total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_dict_json_structure = json.dumps(image_count_dict, indent=4)\n",
    "with open('.\\image_count.json', 'w') as f:\n",
    "        f.write(image_count_dict_json_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def image_resolution_stats(dataset_path):\n",
    "    resolutions = []\n",
    "\n",
    "    # Traverse through each labeled folder (e.g., '01_alb_id', '02_bra_passport', ...)\n",
    "    for label_folder in os.listdir(dataset_path):\n",
    "        label_folder_path = os.path.join(dataset_path, label_folder)\n",
    "        if not os.path.isdir(label_folder_path):\n",
    "            continue\n",
    "        \n",
    "        # Traverse through each document type folder (e.g., 'images/CA', 'images/CS', ...)\n",
    "        images_folder = os.path.join(label_folder_path, 'images')\n",
    "        if not os.path.exists(images_folder):\n",
    "            continue\n",
    "        \n",
    "        for doc_type_folder in os.listdir(images_folder):\n",
    "            doc_type_folder_path = os.path.join(images_folder, doc_type_folder)\n",
    "            if not os.path.isdir(doc_type_folder_path):\n",
    "                continue\n",
    "            \n",
    "            # Iterate through image files\n",
    "            for image_file in os.listdir(doc_type_folder_path):\n",
    "                image_path = os.path.join(doc_type_folder_path, image_file)\n",
    "                if os.path.isfile(image_path):\n",
    "                    image = plt.imread(image_path)\n",
    "                    resolutions.append(image.shape[:2])  # Get image dimensions\n",
    "    \n",
    "    resolutions = np.array(resolutions)\n",
    "    mean_resolution = np.mean(resolutions, axis=0)\n",
    "    min_resolution = np.min(resolutions, axis=0)\n",
    "    max_resolution = np.max(resolutions, axis=0)\n",
    "\n",
    "    return mean_resolution, min_resolution, max_resolution\n",
    "\n",
    "# Calculate image resolution statistics\n",
    "mean_res, min_res, max_res = image_resolution_stats(dataset_path)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Image Resolution Statistics:\")\n",
    "print(f\"  Mean Image Resolution: {mean_res}\")\n",
    "print(f\"  Minimum Image Resolution: {min_res}\")\n",
    "print(f\"  Maximum Image Resolution: {max_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def convert_annotation(json_file, txt_file, image_width, image_height):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        # print((data))\n",
    "    \n",
    "    with open(txt_file, 'w') as f:\n",
    "        # print(data['quad'])\n",
    "        # for annotation in data['quad']:\n",
    "        annotation = data['quad']\n",
    "        # Extract bounding box coordinates (x1, y1, x2, y2, x3, y3, x4, y4)\n",
    "        x1, y1 = annotation[0]\n",
    "        x2, y2 = annotation[1]\n",
    "        x3, y3 = annotation[2]\n",
    "        x4, y4 = annotation[3]\n",
    "            \n",
    "        # Calculate bounding box center and size\n",
    "        x_center = (x1 + x2 + x3 + x4) / 4.0 / image_width\n",
    "        y_center = (y1 + y2 + y3 + y4) / 4.0 / image_height\n",
    "        width = (max(x1, x2, x3, x4) - min(x1, x2, x3, x4)) / image_width\n",
    "        height = (max(y1, y2, y3, y4) - min(y1, y2, y3, y4)) / image_height\n",
    "\n",
    "        # Write to file in YOLO format\n",
    "        class_id = 0  # Assuming single class, update if you have multiple classes\n",
    "        f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "def process_dataset(dataset_path):\n",
    "    for label_folder in os.listdir(dataset_path):\n",
    "        label_folder_path = os.path.join(dataset_path, label_folder)\n",
    "        if not os.path.isdir(label_folder_path):\n",
    "            continue\n",
    "        \n",
    "        images_folder = os.path.join(label_folder_path, 'images')\n",
    "        groundtruth_folder = os.path.join(label_folder_path, 'ground_truth')\n",
    "        if not os.path.exists(images_folder) or not os.path.exists(groundtruth_folder):\n",
    "            continue\n",
    "        \n",
    "        for doc_type_folder in os.listdir(images_folder):\n",
    "            doc_type_folder_path = os.path.join(images_folder, doc_type_folder)\n",
    "            gt_doc_type_folder_path = os.path.join(groundtruth_folder, doc_type_folder)\n",
    "            if not os.path.isdir(doc_type_folder_path) or not os.path.isdir(gt_doc_type_folder_path):\n",
    "                continue\n",
    "            \n",
    "            for image_file in os.listdir(doc_type_folder_path):\n",
    "                if not image_file.endswith('.tif'):\n",
    "                    continue\n",
    "                \n",
    "                image_path = os.path.join(doc_type_folder_path, image_file)\n",
    "                json_file = os.path.join(gt_doc_type_folder_path, image_file.replace('.tif', '.json'))\n",
    "                txt_file = os.path.join(gt_doc_type_folder_path, image_file.replace('.tif', '.txt'))\n",
    "                txt_file = txt_file.replace('ground_truth', 'images')\n",
    "                \n",
    "                # Load image to get dimensions\n",
    "                image = plt.imread(image_path)\n",
    "                image_height, image_width = image.shape[:2]\n",
    "                # print(json_file)\n",
    "                # print(text_file)\n",
    "                # Convert annotation\n",
    "                convert_annotation(json_file, txt_file, image_width, image_height)\n",
    "\n",
    "dataset_path = '.\\midv500_data\\midv500'\n",
    "process_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "current_dir = './'  # Update with your current directory path\n",
    "data_dir = os.path.join(current_dir, 'data')\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "labels_dir = os.path.join(data_dir, 'labels')\n",
    "midv500_dir = 'D:\\playground\\mdfv500\\midv500_data\\midv500'  # Update with your actual path to midv500\n",
    "\n",
    "# Ensure data directory exists, create images and labels directories\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy files from source to destination\n",
    "def copy_files(source_dir, dest_dir):\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            src_file = os.path.join(root, file)\n",
    "            dest_file = dest_dir + '\\\\' + file #os.path.join(dest_dir, os.path.relpath(src_file, source_dir))\n",
    "            os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
    "            shutil.copyfile(src_file, dest_file)\n",
    "            print(f'Copied {src_file} to {dest_file}')\n",
    "\n",
    "# # Copy images from midv500/images to data/images\n",
    "# copy_files(os.path.join(midv500_dir, '01_alb_id/images'), images_dir)\n",
    "# copy_files(os.path.join(midv500_dir, '02_bra_passport/images'), images_dir)\n",
    "# # Add more lines for other folders as needed\n",
    "\n",
    "# # Copy labels from midv500/ground_truth to data/labels\n",
    "# copy_files(os.path.join(midv500_dir, '01_alb_id/labels'), labels_dir)\n",
    "# copy_files(os.path.join(midv500_dir, '02_bra_passport/labels'), labels_dir)\n",
    "# Add more lines for other folders as needed\n",
    "\n",
    "\n",
    "for dir in [x for x in os.walk(midv500_dir)][0][1]:\n",
    "    join_dir_images = dir + '\\\\images'\n",
    "    join_dir_labels = dir + '\\\\labels'\n",
    "    copy_files(os.path.join(midv500_dir, join_dir_images), images_dir)\n",
    "    copy_files(os.path.join(midv500_dir, join_dir_labels), labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_dataset(train_file, val_file):\n",
    "    def check_file_list(file_list):\n",
    "        with open(file_list, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        missing_labels = []\n",
    "        for line in lines:\n",
    "            image_path = line.strip()\n",
    "            label_path = image_path.replace('/images/', '/ground_truth/').replace('.tif', '.txt')\n",
    "            if not os.path.exists(label_path):\n",
    "                missing_labels.append(label_path)\n",
    "        return missing_labels\n",
    "\n",
    "    train_missing = check_file_list(train_file)\n",
    "    val_missing = check_file_list(val_file)\n",
    "\n",
    "    if train_missing:\n",
    "        print(\"Missing labels in training set:\")\n",
    "        for missing in train_missing:\n",
    "            print(missing)\n",
    "    else:\n",
    "        print(\"All training labels are present.\")\n",
    "    \n",
    "    if val_missing:\n",
    "        print(\"Missing labels in validation set:\")\n",
    "        for missing in val_missing:\n",
    "            print(missing)\n",
    "    else:\n",
    "        print(\"All validation labels are present.\")\n",
    "\n",
    "# Update these paths to the locations of your train.txt and val.txt\n",
    "train_file = 'D:/playground/mdfv500/train.txt'\n",
    "val_file = 'D:/playground/mdfv500/val.txt'\n",
    "\n",
    "check_dataset(train_file, val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_dataset_files(dataset_path, output_path, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Create train.txt and val.txt files for a dataset located at dataset_path,\n",
    "    with images in 'images' subfolder and labels in 'labels' subfolder,\n",
    "    and save these lists to output_path.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset_path (str): Path to the dataset directory.\n",
    "    - output_path (str): Path to save the train.txt and val.txt files.\n",
    "    - split_ratio (float): Ratio of training images to total images (default is 0.8).\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(dataset_path, 'images')\n",
    "    labels_dir = os.path.join(dataset_path, 'labels')\n",
    "    \n",
    "    # List all image files\n",
    "    image_files = [f for f in os.listdir(images_dir) if f.endswith('.tif')]\n",
    "    num_images = len(image_files)\n",
    "    num_train = int(num_images * split_ratio)\n",
    "    \n",
    "    # Randomize the order of images\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    train_files = image_files[:num_train]\n",
    "    val_files = image_files[num_train:]\n",
    "    \n",
    "    # Write paths to train.txt and val.txt\n",
    "    with open(os.path.join(output_path, 'train.txt'), 'w') as f:\n",
    "        for file in train_files:\n",
    "            image_path = os.path.join(images_dir, file)\n",
    "            label_file = os.path.splitext(file)[0] + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            f.write(f\"{image_path}\\n\")\n",
    "            # Optionally check if label file exists\n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Warning: Label file '{label_path}' not found for '{image_path}'\")\n",
    "    \n",
    "    with open(os.path.join(output_path, 'val.txt'), 'w') as f:\n",
    "        for file in val_files:\n",
    "            image_path = os.path.join(images_dir, file)\n",
    "            label_file = os.path.splitext(file)[0] + '.txt'\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            f.write(f\"{image_path}\\n\")\n",
    "            # Optionally check if label file exists\n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Warning: Label file '{label_path}' not found for '{image_path}'\")\n",
    "\n",
    "# Example usage:\n",
    "dataset_path = '.\\\\data'\n",
    "output_path = '.\\\\'  # Update with your desired output path\n",
    "create_dataset_files(dataset_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Function to load YOLO label\n",
    "def load_yolo_label(label_path):\n",
    "    with open(label_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return [list(map(float, line.strip().split())) for line in lines]\n",
    "\n",
    "# Function to display image with labels\n",
    "def display_image_with_label(image_path, label_path):\n",
    "    image = Image.open(image_path)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Load labels\n",
    "    labels = load_yolo_label(label_path)\n",
    "    \n",
    "    img_width, img_height = image.size\n",
    "    \n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, width, height = label\n",
    "        x_center *= img_width\n",
    "        y_center *= img_height\n",
    "        width *= img_width\n",
    "        height *= img_height\n",
    "        x_min = x_center - width / 2\n",
    "        y_min = y_center - height / 2\n",
    "        \n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(x_min, y_min, str(int(class_id)), color='red', fontsize=12)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Main code\n",
    "image_dir = '.\\\\data\\\\images'\n",
    "label_dir = '.\\\\data\\\\labels'\n",
    "\n",
    "image_files = os.listdir(image_dir)\n",
    "if image_files:\n",
    "    random_image_file = random.choice(image_files)\n",
    "    image_path = os.path.join(image_dir, random_image_file)\n",
    "    \n",
    "    label_file = random_image_file.replace('.tif', '.txt')  # Assuming labels have the same name with .txt extension\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "    \n",
    "    if os.path.exists(label_path):\n",
    "        display_image_with_label(image_path, label_path)\n",
    "    else:\n",
    "        print(f\"Label file for {random_image_file} not found.\")\n",
    "else:\n",
    "    print(\"No images found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
